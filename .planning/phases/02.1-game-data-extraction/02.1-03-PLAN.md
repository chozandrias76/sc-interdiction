---
phase: 02.1-game-data-extraction
plan: 03
type: execute
---

<objective>
Create extraction pipeline with caching integrated into sc-data-extractor crate.

Purpose: Provide a reliable, cached Rust interface to game data that Phase 3+ can depend on. Avoid re-extracting from the 150GB p4k on every run.
Output: Extended sc-data-extractor crate with DataForge extraction, caching, and typed Wikelo record access.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02.1-game-data-extraction/02.1-RESEARCH.md

**Prior plan outputs:**
@.planning/phases/02.1-game-data-extraction/02.1-01-SUMMARY.md
@.planning/phases/02.1-game-data-extraction/02.1-02-SUMMARY.md
@.planning/phases/02.1-game-data-extraction/DATAFORGE-FINDINGS.md

**Existing crate:**
@crates/sc-data-extractor/src/lib.rs
@crates/sc-data-extractor/Cargo.toml

**Architecture patterns (from research):**
- Tool abstraction layer (trait for extraction)
- Lazy extraction with caching (hash p4k metadata)
- Typed DataForge records (only types we need)

**Key constraints:**
- Must cache extracted data to disk (not re-extract 150GB p4k each run)
- Cache invalidation based on p4k file metadata (size + mtime)
- Only define Rust types for records we actually consume
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add DataForge extraction module to sc-data-extractor</name>
  <files>crates/sc-data-extractor/src/dataforge.rs, crates/sc-data-extractor/src/lib.rs, crates/sc-data-extractor/Cargo.toml</files>
  <action>
Add a new module for DataForge extraction that:

**Cargo.toml changes:**
- Add `which = "6"` for tool detection
- Add `tempfile = "3"` for extraction temp dirs
- Ensure serde_json is available

**dataforge.rs:**
1. `DataForgeExtractor` struct holding:
   - p4k_path: PathBuf
   - cache_dir: PathBuf (default: ~/.cache/sc-interdiction/)
   - extraction_script: PathBuf (scripts/extract_gamedata.py)

2. `extract_or_load()` method:
   - Check if cache exists and is valid (p4k mtime/size hasn't changed)
   - If valid, load from cache
   - If invalid, run extraction script, save to cache
   - Return parsed DataForge data or path to JSON

3. Cache validation:
   - Store `.cache-meta.json` with p4k size, mtime, extraction timestamp
   - On load, compare current p4k metadata with cached metadata
   - If different, re-extract

4. Error handling:
   - Tool not found → clear error with install instructions
   - P4k not found → error with path guidance
   - Extraction failure → capture stderr, report

**lib.rs:**
- Add `pub mod dataforge;`
- Re-export key types
  </action>
  <verify>
```bash
cargo build -p sc-data-extractor
cargo doc -p sc-data-extractor --no-deps
```
  </verify>
  <done>dataforge.rs module exists with DataForgeExtractor, crate compiles, docs generate</done>
</task>

<task type="auto">
  <name>Task 2: Add typed Wikelo record structs based on DATAFORGE-FINDINGS.md</name>
  <files>crates/sc-data-extractor/src/dataforge/types.rs, crates/sc-data-extractor/src/dataforge/mod.rs</files>
  <action>
Based on the findings from Plan 02, create typed Rust structs for the specific record types we need.

**types.rs:**
Define structs for the Wikelo-relevant records discovered in DATAFORGE-FINDINGS.md. Likely includes:
- Contract/mission records (whatever type contains Wikelo contracts)
- Item requirement records
- Reward records

Each struct should:
- Derive Debug, Clone, Deserialize
- Use `#[serde(rename = "...")]` for CamelCase game fields
- Include only fields we actually need (not full record)

**mod.rs:**
- Re-export types
- Add `parse_wikelo_contracts(json_path: &Path) -> Result<Vec<WikieloContract>>` function
- Add `parse_items(json_path: &Path) -> Result<Vec<ItemRecord>>` if items are separate

Use serde's flexible parsing (skip unknown fields) so we're resilient to game updates adding new fields.

Note: The exact struct definitions depend on DATAFORGE-FINDINGS.md from Plan 02. If findings show Wikelo data is in unexpected format, adapt accordingly.
  </action>
  <verify>
```bash
cargo build -p sc-data-extractor
cargo test -p sc-data-extractor
```
  </verify>
  <done>Type structs compile, parsing functions exist, tests pass (if any)</done>
</task>

<task type="auto">
  <name>Task 3: Add localization lookup module</name>
  <files>crates/sc-data-extractor/src/localization.rs</files>
  <action>
Add module for parsing and looking up localization strings from global.ini:

**localization.rs:**
1. `LocalizationStore` struct:
   - HashMap<String, String> for key→value lookup
   - `load(path: &Path)` constructor

2. `parse_global_ini(path: &Path)` function:
   - Handle BOM (UTF-8 with BOM is common)
   - Skip comment lines (starting with ; or #)
   - Parse key=value format
   - Return HashMap

3. `get(&self, key: &str) -> Option<&str>` method

4. Integration with DataForgeExtractor:
   - Add `localization()` method that returns LocalizationStore
   - Lazy load from cache

This enables translating localization keys from DataForge records to human-readable strings.

**lib.rs:**
- Add `pub mod localization;`
- Re-export LocalizationStore
  </action>
  <verify>
```bash
cargo build -p sc-data-extractor
# Quick test with actual global.ini if available:
# cargo run -p sc-data-extractor --example localization_test 2>/dev/null || true
```
  </verify>
  <done>localization.rs module exists, LocalizationStore parses global.ini format, crate compiles</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] sc-data-extractor crate compiles with new modules
- [ ] DataForgeExtractor can cache and validate extraction
- [ ] Typed structs exist for Wikelo-relevant records
- [ ] LocalizationStore can parse global.ini
- [ ] No clippy warnings in new code
</verification>

<success_criteria>
- Extraction pipeline with caching prevents repeated 150GB p4k reads
- Typed Wikelo records ready for Phase 3 data module
- Localization lookup enables human-readable strings
- sc-data-extractor is the single source of truth for game data access
- Phase 2.1 complete, ready for Phase 3: Wikelo Data Module
</success_criteria>

<output>
After completion, create `.planning/phases/02.1-game-data-extraction/02.1-03-SUMMARY.md`:

# Phase 2.1 Plan 03: Extraction Pipeline Summary

**[Substantive one-liner about pipeline capabilities]**

## Accomplishments

- DataForgeExtractor with caching
- Typed Wikelo record structs
- LocalizationStore for string lookup

## Files Created/Modified

- `crates/sc-data-extractor/src/dataforge.rs` - Extraction with caching
- `crates/sc-data-extractor/src/dataforge/types.rs` - Typed records
- `crates/sc-data-extractor/src/localization.rs` - String lookup

## Decisions Made

[Caching strategy, type definitions, etc.]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Phase Readiness

- Phase 2.1 complete
- Ready for Phase 3: Wikelo Data Module
- sc-data-extractor provides typed access to Wikelo contracts and items
</output>
